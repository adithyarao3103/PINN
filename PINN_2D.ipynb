{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PINN for PDEs with two inputs\n",
    "\n",
    "Here we consider the 1D wave equation with inputs $x$ and $t$, \n",
    "\n",
    "$$\n",
    " \\frac{\\partial^2 f}{\\partial t^2} - v\\cdot \\frac{\\partial^2 f}{\\partial x^2} = 0\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<contextlib.ExitStack at 0x1ea8302b950>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import matplotlib.animation\n",
    "plt.rcParams[\"animation.html\"] = \"jshtml\"\n",
    "plt.rcParams['figure.dpi'] = 100  \n",
    "plt.ioff()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defnining a general neural network class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(tf.keras.Model):\n",
    "    def __init__(\n",
    "            self, \n",
    "            num_inputs: int=1,\n",
    "            num_hidden_layers: int=1,\n",
    "            num_neurons: int=1,\n",
    "            activation: str = 'tanh'\n",
    "    )->None:\n",
    "        super().__init__()\n",
    "        self.num_inputs = num_inputs\n",
    "        self.num_hidden_layers = num_hidden_layers\n",
    "        self.num_neurons = num_neurons\n",
    "\n",
    "        NNLayers = []\n",
    "        for _ in range(num_hidden_layers):\n",
    "            NNLayers.append(tf.keras.layers.Dense(units=num_neurons, activation=activation)) # the hidden layers\n",
    "        NNLayers.append(tf.keras.layers.Dense(units=1)) # the output layer\n",
    "\n",
    "        self.NNLayers = NNLayers\n",
    "\n",
    "    def call(\n",
    "            self,\n",
    "            input: tf.Tensor\n",
    "    )->tf.Tensor: # the neural network call implements the forward call, where it runs the input through the first layer, and then feeds the output of the first layer to the second layer and so on\n",
    "        output = tf.reshape(input, shape=(-1, self.num_inputs))\n",
    "        for layer in self.NNLayers:\n",
    "            output = layer(output)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem specific defninition of the loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_LAYERS = 20\n",
    "NUM_NEURONS = 10\n",
    "EPOCHS = 10000 #how many times the training step is performed\n",
    "BATCH_SIZE = 100 # how many input values are considered for each epoch\n",
    "LEARNING_RATE = 5e-5\n",
    "TOLERANCE = 1e-5\n",
    "NUM_INPUTS = 2\n",
    "\n",
    "V=1.5\n",
    "\n",
    "T_DOMAIN = (0.0, 5.0)\n",
    "X_DOMAIN = (0.0, 2*np.pi)\n",
    "T_BOUNDARY = tf.concat([tf.linspace(X_DOMAIN[0], X_DOMAIN[1], BATCH_SIZE)[:, tf.newaxis], tf.fill([BATCH_SIZE,1], T_DOMAIN[0])], axis=1)\n",
    "X_BOUNDARY_0 = tf.concat([tf.fill([BATCH_SIZE,1], X_DOMAIN[0]), tf.linspace(T_DOMAIN[0], T_DOMAIN[1], BATCH_SIZE)[:, tf.newaxis]], axis=1)\n",
    "X_BOUNDARY_1 = tf.concat([tf.fill([BATCH_SIZE,1], X_DOMAIN[1]), tf.linspace(T_DOMAIN[0], T_DOMAIN[1], BATCH_SIZE)[:, tf.newaxis]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def loss_fun(\n",
    "        model: tf.keras.Model,\n",
    "        input: tf.Tensor\n",
    ")->tf.Tensor:\n",
    "    x = tf.gather(input, [0], axis=1)\n",
    "    t = tf.gather(input, [1], axis=1)\n",
    "    with tf.GradientTape(persistent=True) as tape: # required in order to calculate the derivatives\n",
    "        tape.watch(x)\n",
    "        tape.watch(t)\n",
    "        u = model(tf.concat([x,t], axis=1))\n",
    "        u_x = tape.gradient(u, x)\n",
    "        u_t = tape.gradient(u, t) \n",
    "\n",
    "    u_xx = tape.gradient(u_x, x) \n",
    "    u_tt = tape.gradient(u_t, t) \n",
    "\n",
    "    del tape\n",
    "\n",
    "    pde = u_tt - V*V*u_xx # the PDE \n",
    "    boundary_t = model(T_BOUNDARY) - tf.math.sin(tf.gather(T_BOUNDARY, [0], axis=1)- V*tf.gather(T_BOUNDARY, [1], axis=1)) # boundary condition sin wave at t=0\n",
    "    boundary_x_0 = model(X_BOUNDARY_0) - tf.math.sin(tf.gather(X_BOUNDARY_0, [0], axis=1) - V*tf.gather(X_BOUNDARY_0, [1], axis=1)) # boundary condition sin wave at x=x0\n",
    "    boundary_x_1 = model(X_BOUNDARY_1) - tf.math.sin(tf.gather(X_BOUNDARY_1, [0], axis=1) - V*tf.gather(X_BOUNDARY_1, [1], axis=1)) # boundary condition sin wave at x=x1\n",
    "\n",
    "    interior_loss = tf.reduce_mean(tf.square(pde)) # mean square of the PDE forms the PDE loss\n",
    "    boundary_loss = tf.reduce_mean(tf.square(boundary_x_0) + tf.square(boundary_x_1) + tf.square(boundary_t)) # square of the boundary term forms the boundary loss\n",
    "\n",
    "    loss = interior_loss + boundary_loss\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_plot = tf.linspace(X_DOMAIN[0], X_DOMAIN[1], BATCH_SIZE)[:, tf.newaxis]\n",
    "t_plot = tf.linspace(T_DOMAIN[0], T_DOMAIN[1], BATCH_SIZE)[:, tf.newaxis]\n",
    "X_mesh, T_mesh = tf.meshgrid(x_plot, t_plot)\n",
    "X_pred = tf.reshape(X_mesh, shape=(-1, 1))\n",
    "T_pred = tf.reshape(T_mesh, shape=(-1, 1))\n",
    "\n",
    "plt.scatter(X_pred, T_pred, s=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.\n",
      "Epoch: 0, Loss: 1.5393966436386108\n",
      "Epoch: 500, Loss: 0.7559066414833069\n",
      "Epoch: 1000, Loss: 0.49113237857818604\n",
      "Epoch: 1500, Loss: 0.33474287390708923\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [6], line 21\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(EPOCHS):\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;66;03m# input_batch = tf.keras.random.uniform(shape=(BATCH_SIZE, NUM_INPUTS), minval=[X_DOMAIN[0], T_DOMAIN[0]], maxval=[X_DOMAIN[1], T_DOMAIN[1]], dtype=tf.float32) #randomly sample BATCH_SIZE number of points from the domain\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mINPUT\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# run the train step for the given batch\u001b[39;00m\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m500\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     23\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32md:\\Users\\adith\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32md:\\Users\\adith\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32md:\\Users\\adith\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:869\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    866\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    867\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    868\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 869\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    870\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[0;32m    871\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    872\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    873\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    874\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    875\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32md:\\Users\\adith\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Users\\adith\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32md:\\Users\\adith\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32md:\\Users\\adith\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32md:\\Users\\adith\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1552\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1550\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1551\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1552\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1553\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1554\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1555\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1556\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1557\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1558\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1560\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1561\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1562\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1566\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1567\u001b[0m   )\n",
      "File \u001b[1;32md:\\Users\\adith\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "INPUT = tf.concat([X_pred, T_pred], axis=1)\n",
    "\n",
    "model = NN(num_inputs=NUM_INPUTS, num_hidden_layers= NUM_LAYERS, num_neurons=NUM_NEURONS)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
    "\n",
    "@tf.function\n",
    "def train_step(model, input): # function for one single training step\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = loss_fun(model, input)\n",
    "\n",
    "    gradients = tape.gradient(loss, model.trainable_variables) # calculate the gradients of the loss with respect to \\theta\n",
    "\n",
    "    del tape\n",
    "\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables)) # optimize the parameters to minimize the loss\n",
    "\n",
    "    return loss\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    # input_batch = tf.keras.random.uniform(shape=(BATCH_SIZE, NUM_INPUTS), minval=[X_DOMAIN[0], T_DOMAIN[0]], maxval=[X_DOMAIN[1], T_DOMAIN[1]], dtype=tf.float32) #randomly sample BATCH_SIZE number of points from the domain\n",
    "    loss = train_step(model, INPUT) # run the train step for the given batch\n",
    "    if epoch % 500 == 0:\n",
    "        print(f'Epoch: {epoch}, Loss: {loss}')\n",
    "    if loss<=TOLERANCE:\n",
    "        print(f\"Converged at epoch {epoch}\")\n",
    "        break\n",
    "\n",
    "clear_output()\n",
    "print(f\"Converged at epoch {epoch}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction and Plotting!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model(INPUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.grid(True)\n",
    "\n",
    "def animate(i):\n",
    "    plt.cla()\n",
    "    plt.plot(x_plot, y_pred[i*BATCH_SIZE : (i+1)*BATCH_SIZE])\n",
    "    plt.xlim(X_DOMAIN[0], X_DOMAIN[1])  \n",
    "    plt.ylim(-2,2)\n",
    "\n",
    "matplotlib.animation.FuncAnimation(fig, animate, frames=BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_pred, T_pred, c=y_pred, s=4)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('t')\n",
    "cbar = plt.colorbar()\n",
    "cbar.set_label('u', rotation=0)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits import mplot3d\n",
    "\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.scatter(tf.gather(INPUT, [0], axis=1), tf.gather(INPUT, [1], axis=1), y_pred, alpha=0.1)\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('t')\n",
    "ax.set_zlabel('u')\n",
    "ax.view_init(-130, 45)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
